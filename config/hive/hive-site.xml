<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?><!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
--><configuration>
  <!-- WARNING!!! This file is auto generated for documentation purposes ONLY! -->
  <!-- WARNING!!! Any changes you make to this file will be ignored by Hive.   -->
  <!-- WARNING!!! You must make your changes in hive-site.xml instead.         -->
  <!-- Hive Execution Parameters -->

    <property>
        <name>hive.metastore.event.db.notification.api.auth</name>
         <value>false</value>
         <description>
           Should metastore do authorization against database notification related APIs such as get_next_notification.
           If set to true, then only the superusers in proxy settings have the permission
         </description>
       </property>
        <property>
       <name>javax.jdo.option.ConnectionDriverName</name>
       <value>org.postgresql.Driver</value>
       <description>Driver class name for a JDBC metastore</description>
    </property>
    <property>
       <name>javax.jdo.option.ConnectionURL</name>
       <value>CONNECTION_URL</value>
       <description>
         JDBC connect string for a JDBC metastore.
         To use SSL to encrypt/authenticate the connection, provide database-specific SSL flag in the connection URL.
         For example, jdbc:postgresql://myhost/db?ssl=true for postgres database.
       </description>
    </property>

    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>CONNECTION_USERNAME</value>
        <description>Username to use against metastore database</description>
      </property>
    <property>
       <name>javax.jdo.option.ConnectionPassword</name>
       <value>CONNECTION_PASSWORD</value>
       <description>password to use against metastore database</description>
    </property>
    <property>
       <name>hive.metastore.uris</name>
       <value>thrift://hadoop-master:9083</value>
       <description>Thrift URI for the remote metastore. Used by metastore client to connect to remote metastore.</description>
    </property>
    <property>
       <name>hive.metastore.db.type</name>
       <value>postgres</value>
       <description>
         Expects one of [derby, oracle, mysql, mssql, postgres].
         Type of database used by the metastore. Information schema JDBCStorageHandler depend on it.
       </description>
    </property>
    <property>
    <name>hive.server2.thrift.min.worker.threads</name>
    <value>5</value>
    <description>Minimum number of Thrift worker threads</description>
  </property>
  <property>
    <name>hive.server2.thrift.max.worker.threads</name>
    <value>500</value>
    <description>Maximum number of Thrift worker threads</description>
  </property>
  <property>
    <name>hive.server2.thrift.exponential.backoff.slot.length</name>
    <value>100ms</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is msec if not specified.
      Binary exponential backoff slot time for Thrift clients during login to HiveServer2,
      for retries until hitting Thrift client timeout
    </description>
  </property>
  <property>
    <name>hive.server2.thrift.login.timeout</name>
    <value>20s</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is sec if not specified.
      Timeout for Thrift clients during login to HiveServer2
    </description>
  </property>
  <property>
    <name>hive.server2.thrift.worker.keepalive.time</name>
    <value>60s</value>
    <description>
      Expects a time value with unit (d/day, h/hour, m/min, s/sec, ms/msec, us/usec, ns/nsec), which is sec if not specified.
      Keepalive time (in seconds) for an idle worker thread. When the number of workers exceeds min workers, excessive threads are killed after this time interval.
    </description>
  </property>
    <property>
    <name>hive.server2.thrift.port</name>
    <value>10000</value>
    <description>Port number of HiveServer2 Thrift interface when hive.server2.transport.mode is 'binary'.</description>
  </property>
    <property>
    <name>hive.server2.thrift.bind.host</name>
    <value>hadoop-master</value>
    <description>Bind host on which to run the HiveServer2 Thrift service.</description>
  </property>
    <property>
    <name>hive.server2.thrift.http.path</name>
    <value>cliservice</value>
    <description>Path component of URL endpoint when in HTTP mode.</description>
  </property>
    <property>
    <name>hive.server2.transport.mode</name>
    <value>binary</value>
    <description>
      Expects one of [binary, http].
      Transport mode of HiveServer2.
    </description>
  </property>
<property>
  <name>hive.tez.java.opts</name>
  <value> -Dlog4j.configurationFile=tez-container-log4j2.properties -Dtez.container.log.level=INFO -Dtez.container.root.logger=CLA </value>
</property>

<property>
  <name>tez.am.launch.cmd-opts</name>
  <value> -Dlog4j.configurationFile=tez-container-log4j2.properties -Dtez.container.log.level=INFO -Dtez.container.root.logger=CLA </value>
</property>

<property>
  <name>hive.orc.splits.ms.footer.cache.enabled</name>
  <value>true</value>
</property>

<property>
  <name>hive.join.inner.residual</name>
  <value>true</value>
</property>

<property>
  <name>hive.stats.fetch.bitvector</name>
  <value>true</value>
</property>

<property>
  <name>hive.tez.cartesian-product.enabled</name>
  <value>true</value>
</property>

<property>
  <name>yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage</name>
  <value>99</value>
</property>

<property>
  <name>hive.query.results.cache.enabled</name>
  <value>false</value>
</property>
    <property>
  <name>hive.stats.fetch.column.stats</name>
  <value>true</value>
  <description>Use column stats to annotate stats for physical optimization phase</description>
</property>
<property>
  <name>hive.stats.dbclass</name>
  <value>fs</value>
  <description>The default storatge that stores temporary hive statistics. Currently, fs type is supported</description>
</property>
    <property>
  <name>hive.default.rcfile.serde</name>
  <value>org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe</value>
  <description>The default SerDe hive will use for the rcfile format</description>
</property>
    <property>
  <name>fs.pfile.impl</name>
  <value>org.apache.hadoop.fs.ProxyLocalFileSystem</value>
  <description>A proxy for local file system used for cross file system testing</description>
</property>

<property>
  <name>hive.exec.mode.local.auto</name>
  <value>false</value>
  <description>
    Let hive determine whether to run in local mode automatically
    Disabling this for tests so that minimr is not affected
  </description>
</property>

<property>
  <name>hive.auto.convert.join</name>
  <value>false</value>
  <description>Whether Hive enable the optimization about converting common join into mapjoin based on the input file size</description>
</property>

<property>
  <name>hive.tez.input.format</name>
  <value>org.apache.hadoop.hive.ql.io.HiveInputFormat</value>
  <description>The default input format for tez. Tez groups splits in the AM.</description>
</property>
    <property>
  <name>hive.merge.tezfiles</name>
  <value>false</value>
  <description>Merge small files at the end of a Tez DAG</description>
</property>
    <property>
  <name>hive.tez.container.size</name>
  <value>128</value>
  <description></description>
</property>
    <property>
     <name>hive.support.concurrency</name>
     <value>true</value>
</property>

<property>
     <name>hive.txn.manager</name>
     <value>org.apache.hadoop.hive.ql.lockmgr.DbTxnManager</value>
</property>

<property>
     <name>name>hive.enforce.bucketing</name>
     <value>true</value>
</property>

<property>
     <name>hive.exec.dynamic.partition.mode</name>
     <value>nonstrict</value>
</property>
    <property>
     <name>hive.compactor.initiator.on</name>
     <value>true</value>
</property>
<property>
     <name>hive.compactor.worker.threads</name>
     <value>3</value>
</property>
</configuration>